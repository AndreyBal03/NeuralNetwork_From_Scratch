
# Neural Network from scratch

For this weekend, I got bored, so I decided to try something new... A complete Neural Network Model (MLP) constructed by math that performs binary classification.

The layers are represented as matrix multiplication to simplify the operations.

I used the sigmoid function as my activation function.

All the optimization is done with the Backpropagation algorithm using the loss function "Binary Cross Entropy."

Feel free to change the architecture of the Neural Network to adapt it for more datasets.
## Installation

Install my project

```bash
  git clone https://github.com/AndreyBal03/NeuralNetwork_From_Scratch.git
  cd NeuralNetwork_From_Scratch
  pip install -r requirements.txt
  python main.py
```
    